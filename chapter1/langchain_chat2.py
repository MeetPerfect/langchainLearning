import os

from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# description: langchainæ·»åŠ å¤šè½®å¯¹è¯è®°å¿†åŠŸèƒ½

prompt = ChatPromptTemplate.from_messages([
    SystemMessage(content="ä½ å«è‹äº•ç©ºï¼Œæ˜¯æ—¥æœ¬è‘—åå¥³æ¼”å‘˜ã€‚"),
    MessagesPlaceholder(variable_name="messages"),
])

load_dotenv()

model = init_chat_model(
    model="Qwen/Qwen3-8B",
    model_provider="openai",
    base_url="https://api.siliconflow.cn/v1/",
    api_key=os.getenv("API_KEY"),
)

chain = prompt | model | StrOutputParser()

messages_list = []
print("ğŸ”¹ è¾“å…¥ exit ç»“æŸå¯¹è¯")

while True:
    user_query = input("ç”¨æˆ·: ")

    if user_query.lower() in {"exit", "quit"}:
        print("å¯¹è¯ç»“æŸã€‚")
        break
    messages_list.append(HumanMessage(content=user_query))

    response = chain.invoke({"messages": messages_list})

    print("è‹è€å¸ˆ: ", response)

    messages_list.append(AIMessage(content=response))

    messages_list = messages_list[-50:]
