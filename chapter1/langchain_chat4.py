import os

import gradio as gr
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# description: langchainæ·»åŠ å¤šè½®å¯¹è¯è®°å¿†åŠŸèƒ½

load_dotenv()

prompt = ChatPromptTemplate.from_messages([
    SystemMessage(content="ä½ å«è‹äº•ç©ºï¼Œæ˜¯æ—¥æœ¬è‘—åå¥³æ¼”å‘˜ã€‚"),
    MessagesPlaceholder(variable_name="messages"),
])



model = init_chat_model(
    model="Qwen/Qwen3-8B",
    model_provider="openai",
    base_url="https://api.siliconflow.cn/v1/",
    api_key=os.getenv("API_KEY"),
)

chain = prompt | model | StrOutputParser()

CSS = """
.main-container {max-width: 1200px; margin: 0 auto; padding: 20px;}
.header-text {text-align: center; margin-bottom: 20px;}
"""


def create_chatbot():
    with gr.Blocks(title="èŠå¤©æœºå™¨äºº", css=CSS) as demo:
        with gr.Column(elem_classes=["main-container"]):
            gr.Markdown("# ğŸ¤– LangChainæ™ºèƒ½å¯¹è¯æœºå™¨äººç³»ç»Ÿ", elem_classes=["header-text"])

            chatbot = gr.Chatbot(
                height=500,
                avatar_images=(
                    "https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/72x72/1f004.png",
                    "https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f916.png",
                ),
            )

            msg = gr.Textbox(placeholder="è¯·è¾“å…¥ä½ çš„æ¶ˆæ¯ï¼Œç„¶åæŒ‰å›è½¦é”®å‘é€...", container=False, scale=7)
            submit = gr.Button("å‘é€", scale=1, variant="primary")
            clear = gr.Button("æ¸…ç©º", scale=1)

        state = gr.State([])

        async def response(user_msg: str, chat_history: list, messages_list: list):
            if not user_msg.strip():
                yield "", chat_history, messages_list
                return

            messages_list.append(HumanMessage(content=user_msg))
            chat_history = chat_history + [
                {"role": "user", "content": user_msg},
                {"role": "assistant", "content": ""}
            ]
            yield "", chat_history, messages_list

            partial = ""
            async for chunk in chain.astream({"messages": messages_list}):
                partial += chunk
                chat_history[-1] = {"role": "assistant", "content": partial}
                yield "", chat_history, messages_list

            messages_list.append(AIMessage(content=partial))

            messages_list = messages_list[-50:]

            # 5) æœ€ç»ˆè¿”å›ï¼ˆGradio éœ€è¦æŠŠæ–°çš„ state ä¼ å›ï¼‰
            yield "", chat_history, messages_list

        def clear_history():
            return [], "", []

        msg.submit(response, [msg, chatbot, state], [msg, chatbot, state])
        submit.click(response, [msg, chatbot, state], [msg, chatbot, state])
        clear.click(clear_history, outputs=[chatbot, msg, state])

    return demo


demo = create_chatbot()

demo.launch(server_name="0.0.0.0", server_port=7860, share=False, debug=True)
